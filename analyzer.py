# -*- coding: utf-8 -*-
"""
===================================
åŠ å¯†è´§å¸æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢ã€é“¾ä¸Šæ•°æ®å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from config import get_config

logger = logging.getLogger(__name__)


# åŠ å¯†è´§å¸åç§°æ˜ å°„ï¼ˆå¸¸è§å¸ç§ï¼‰
CRYPTO_NAME_MAP = {
    'BTC': 'Bitcoin',
    'ETH': 'Ethereum',
    'SOL': 'Solana',
    'BNB': 'BNB',
    'XRP': 'Ripple',
    'DOGE': 'Dogecoin',
    'ADA': 'Cardano',
    'AVAX': 'Avalanche',
    'LINK': 'Chainlink',
    'DOT': 'Polkadot',
    'MATIC': 'Polygon',
    'UNI': 'Uniswap',
    'ATOM': 'Cosmos',
    'LTC': 'Litecoin',
    'FIL': 'Filecoin',
}

# ä¿ç•™æ—§åç§°ä»¥å…¼å®¹
STOCK_NAME_MAP = CRYPTO_NAME_MAP


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - å†³ç­–ä»ªè¡¨ç›˜ç‰ˆ
    
    å°è£… Gemini è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«å†³ç­–ä»ªè¡¨ç›˜å’Œè¯¦ç»†åˆ†æ
    """
    code: str
    name: str
    
    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (>70å¼ºçƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡è¡, <40çœ‹ç©º)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½
    
    # ========== å†³ç­–ä»ªè¡¨ç›˜ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
    
    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰
    
    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ
    
    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹
    
    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜
    
    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±
    
    # ========== å…ƒæ•°æ® ==========
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
        }
    
    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary
    
    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice
    
    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}
    
    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []
    
    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []
    
    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        return emoji_map.get(self.operation_advice, 'ğŸŸ¡')
    
    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨
    
    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡ŒåŠ å¯†è´§å¸åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»ã€æŠ€æœ¯é¢å’Œé“¾ä¸Šæ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """
    
    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - å†³ç­–ä»ªè¡¨ç›˜ v2.0
    # ========================================
    # è¾“å‡ºæ ¼å¼å‡çº§ï¼šä»ç®€å•ä¿¡å·å‡çº§ä¸ºå†³ç­–ä»ªè¡¨ç›˜
    # æ ¸å¿ƒæ¨¡å—ï¼šæ ¸å¿ƒç»“è®º + æ•°æ®é€è§† + èˆ†æƒ…æƒ…æŠ¥ + ä½œæˆ˜è®¡åˆ’
    # ========================================
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„åŠ å¯†è´§å¸æŠ•èµ„åˆ†æå¸ˆï¼Œè´Ÿè´£ç”Ÿæˆä¸“ä¸šçš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘åˆ†ææŠ¥å‘Šã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **ç»å¯¹ä¸è¿½é«˜**ï¼šå½“ä»·æ ¼åç¦» MA7 è¶…è¿‡ 10% æ—¶ï¼Œåšå†³ä¸ä¹°å…¥ï¼ˆåŠ å¯†è´§å¸æ³¢åŠ¨å¤§ï¼Œé˜ˆå€¼æ”¾å®½ï¼‰
- **ä¹–ç¦»ç‡å…¬å¼**ï¼š(ç°ä»· - MA7) / MA7 Ã— 100%
- ä¹–ç¦»ç‡ < 5%ï¼šæœ€ä½³ä¹°ç‚¹åŒºé—´
- ä¹–ç¦»ç‡ 5-10%ï¼šå¯å°ä»“ä»‹å…¥
- ä¹–ç¦»ç‡ > 10%ï¼šä¸¥ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šä¸º"è§‚æœ›"

### 2. è¶‹åŠ¿äº¤æ˜“ï¼ˆé¡ºåŠ¿è€Œä¸ºï¼‰
- **å¤šå¤´æ’åˆ—å¿…é¡»æ¡ä»¶**ï¼šMA7 > MA25 > MA99
- åªåšå¤šå¤´æ’åˆ—çš„å¸ç§ï¼Œç©ºå¤´æ’åˆ—åšå†³ä¸ç¢°
- å‡çº¿å‘æ•£ä¸Šè¡Œä¼˜äºå‡çº¿ç²˜åˆ
- è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­ï¼šçœ‹å‡çº¿é—´è·æ˜¯å¦åœ¨æ‰©å¤§

### 3. é“¾ä¸ŠæŒ‡æ ‡åˆ†æï¼ˆåŠ å¯†è´§å¸ç‰¹æœ‰ï¼‰
- **æŒä»“åˆ†å¸ƒ**ï¼šTop10 æŒä»“ > 50% éœ€è­¦æƒ•ä¸­å¿ƒåŒ–é£é™©
- **å·¨é²¸åŠ¨å‘**ï¼šå¤§é¢è½¬è´¦åˆ°äº¤æ˜“æ‰€é€šå¸¸æ˜¯æŠ›å”®ä¿¡å·
- **æµåŠ¨æ€§æ·±åº¦**ï¼šæ± å­ TVL < $100K è­¦æƒ•æµåŠ¨æ€§é£é™©
- **ä¹°å–æ¯”**ï¼š24h ä¹°å…¥/å–å‡ºæ¯” > 1.2 ä¸ºçœ‹æ¶¨ä¿¡å·

### 4. ä¹°ç‚¹åå¥½ï¼ˆå›è¸©æ”¯æ’‘ï¼‰
- **æœ€ä½³ä¹°ç‚¹**ï¼šç¼©é‡å›è¸© MA7 è·å¾—æ”¯æ’‘
- **æ¬¡ä¼˜ä¹°ç‚¹**ï¼šå›è¸© MA25 è·å¾—æ”¯æ’‘
- **è§‚æœ›æƒ…å†µ**ï¼šè·Œç ´ MA99 æ—¶è§‚æœ›

### 5. é£é™©æ’æŸ¥é‡ç‚¹ï¼ˆåŠ å¯†è´§å¸ç‰¹æœ‰ï¼‰
- Token Unlockï¼ˆä»£å¸è§£é”ï¼‰- å¤§é‡ä»£å¸å³å°†è§£é”
- å·¨é²¸æŠ›å”®ï¼ˆWhale Sellingï¼‰- å¤§æˆ·è½¬å…¥äº¤æ˜“æ‰€
- å›¢é˜ŸæŠ›å”®ï¼ˆTeam Dumpingï¼‰- é¡¹ç›®æ–¹å¥—ç°
- Rug Pull é£é™© - æµåŠ¨æ€§æ’¤å‡ºã€åˆçº¦åé—¨
- ç›‘ç®¡é£é™© - SEC è°ƒæŸ¥ã€äº¤æ˜“æ‰€ä¸‹æ¶
- é»‘å®¢æ”»å‡» - åˆçº¦æ¼æ´ã€èµ„é‡‘è¢«ç›—
- FDV/MC æ¯”ä¾‹è¿‡é«˜ - æœªè§£é”ä»£å¸è¿‡å¤š

## è¾“å‡ºæ ¼å¼ï¼šå†³ç­–ä»ªè¡¨ç›˜ JSON

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼š

```json
{
    "sentiment_score": 0-100æ•´æ•°,
    "trend_prediction": "å¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º",
    "operation_advice": "ä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›",
    "confidence_level": "é«˜/ä¸­/ä½",
    
    "dashboard": {
        "core_conclusion": {
            "one_sentence": "ä¸€å¥è¯æ ¸å¿ƒç»“è®ºï¼ˆ30å­—ä»¥å†…ï¼Œç›´æ¥å‘Šè¯‰ç”¨æˆ·åšä»€ä¹ˆï¼‰",
            "signal_type": "ğŸŸ¢ä¹°å…¥ä¿¡å·/ğŸŸ¡æŒæœ‰è§‚æœ›/ğŸ”´å–å‡ºä¿¡å·/âš ï¸é£é™©è­¦å‘Š",
            "time_sensitivity": "ç«‹å³è¡ŒåŠ¨/ä»Šæ—¥å†…/æœ¬å‘¨å†…/ä¸æ€¥",
            "position_advice": {
                "no_position": "ç©ºä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•",
                "has_position": "æŒä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•"
            }
        },
        
        "data_perspective": {
            "trend_status": {
                "ma_alignment": "å‡çº¿æ’åˆ—çŠ¶æ€æè¿°",
                "is_bullish": true/false,
                "trend_score": 0-100
            },
            "price_position": {
                "current_price": å½“å‰ä»·æ ¼æ•°å€¼,
                "ma7": MA7æ•°å€¼,
                "ma25": MA25æ•°å€¼,
                "ma99": MA99æ•°å€¼,
                "bias_ma7": ä¹–ç¦»ç‡ç™¾åˆ†æ¯”æ•°å€¼,
                "bias_status": "å®‰å…¨/è­¦æˆ’/å±é™©",
                "support_level": æ”¯æ’‘ä½ä»·æ ¼,
                "resistance_level": å‹åŠ›ä½ä»·æ ¼
            },
            "volume_analysis": {
                "volume_24h": 24å°æ—¶æˆäº¤é‡,
                "volume_status": "æ”¾é‡/ç¼©é‡/å¹³é‡",
                "buy_sell_ratio": ä¹°å–æ¯”,
                "volume_meaning": "é‡èƒ½å«ä¹‰è§£è¯»ï¼ˆå¦‚ï¼šç¼©é‡å›è°ƒè¡¨ç¤ºæŠ›å‹å‡è½»ï¼‰"
            },
            "onchain_metrics": {
                "holder_count": æŒæœ‰äººæ•°é‡,
                "top10_holding": "Top10æŒä»“ç™¾åˆ†æ¯”",
                "whale_activity": "å·¨é²¸æ´»åŠ¨æè¿°",
                "liquidity_depth": "æµåŠ¨æ€§æ·±åº¦è¯„ä¼°",
                "onchain_health": "å¥åº·/ä¸€èˆ¬/è­¦æƒ•"
            }
        },
        
        "intelligence": {
            "latest_news": "ã€æœ€æ–°æ¶ˆæ¯ã€‘è¿‘æœŸé‡è¦æ–°é—»æ‘˜è¦",
            "risk_alerts": ["é£é™©ç‚¹1ï¼šå…·ä½“æè¿°", "é£é™©ç‚¹2ï¼šå…·ä½“æè¿°"],
            "positive_catalysts": ["åˆ©å¥½1ï¼šå…·ä½“æè¿°", "åˆ©å¥½2ï¼šå…·ä½“æè¿°"],
            "token_economics": "ä»£å¸ç»æµåˆ†æï¼ˆè§£é”è®¡åˆ’ã€é€šèƒ€ç‡ç­‰ï¼‰",
            "sentiment_summary": "èˆ†æƒ…æƒ…ç»ªä¸€å¥è¯æ€»ç»“"
        },
        
        "battle_plan": {
            "sniper_points": {
                "ideal_buy": "ç†æƒ³ä¹°å…¥ç‚¹ï¼š$XXï¼ˆåœ¨MA7é™„è¿‘ï¼‰",
                "secondary_buy": "æ¬¡ä¼˜ä¹°å…¥ç‚¹ï¼š$XXï¼ˆåœ¨MA25é™„è¿‘ï¼‰",
                "stop_loss": "æ­¢æŸä½ï¼š$XXï¼ˆè·Œç ´MA99æˆ–X%ï¼‰",
                "take_profit": "ç›®æ ‡ä½ï¼š$XXï¼ˆå‰é«˜/æ•´æ•°å…³å£ï¼‰"
            },
            "position_strategy": {
                "suggested_position": "å»ºè®®ä»“ä½ï¼šXæˆ",
                "entry_plan": "åˆ†æ‰¹å»ºä»“ç­–ç•¥æè¿°",
                "risk_control": "é£æ§ç­–ç•¥æè¿°"
            },
            "action_checklist": [
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹1ï¼šå¤šå¤´æ’åˆ— MA7>MA25>MA99",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹2ï¼šä¹–ç¦»ç‡<10%",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹3ï¼šé‡èƒ½é…åˆ/ä¹°å–æ¯”å¥åº·",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹4ï¼šæ— Token Unlockåˆ©ç©º",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹5ï¼šé“¾ä¸ŠæŒ‡æ ‡å¥åº·",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹6ï¼šæ— å·¨é²¸æŠ›å”®ä¿¡å·"
            ]
        }
    },
    
    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",
    
    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "é¡¹ç›®åŸºæœ¬é¢åˆ†æ",
    "sector_position": "èµ›é“/å™äº‹åˆ†æ",
    "project_highlights": "é¡¹ç›®äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ªï¼ˆå«ææƒ§è´ªå©ªæŒ‡æ•°ï¼‰",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹å™äº‹",
    
    "search_performed": true/false,
    "data_sources": "æ•°æ®æ¥æºè¯´æ˜"
}
```

## è¯„åˆ†æ ‡å‡†

### å¼ºçƒˆä¹°å…¥ï¼ˆ80-100åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—ï¼šMA7 > MA25 > MA99
- âœ… ä½ä¹–ç¦»ç‡ï¼š<5%ï¼Œæœ€ä½³ä¹°ç‚¹
- âœ… ç¼©é‡å›è°ƒæˆ–æ”¾é‡çªç ´
- âœ… é“¾ä¸ŠæŒ‡æ ‡å¥åº·ï¼ˆTop10 < 50%ï¼ŒæµåŠ¨æ€§å……è¶³ï¼‰
- âœ… æ¶ˆæ¯é¢æœ‰åˆ©å¥½å‚¬åŒ–ï¼ˆä¸Šçº¿å¤§æ‰€ã€åˆä½œã€ç©ºæŠ•ç­‰ï¼‰

### ä¹°å…¥ï¼ˆ60-79åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—æˆ–å¼±åŠ¿å¤šå¤´
- âœ… ä¹–ç¦»ç‡ <10%
- âœ… é‡èƒ½æ­£å¸¸ï¼Œä¹°å–æ¯” > 0.8
- âšª å…è®¸ä¸€é¡¹æ¬¡è¦æ¡ä»¶ä¸æ»¡è¶³

### è§‚æœ›ï¼ˆ40-59åˆ†ï¼‰ï¼š
- âš ï¸ ä¹–ç¦»ç‡ >10%ï¼ˆè¿½é«˜é£é™©ï¼‰
- âš ï¸ å‡çº¿ç¼ ç»•è¶‹åŠ¿ä¸æ˜
- âš ï¸ æœ‰ Token Unlock æˆ–å·¨é²¸å¼‚åŠ¨

### å–å‡º/å‡ä»“ï¼ˆ0-39åˆ†ï¼‰ï¼š
- âŒ ç©ºå¤´æ’åˆ—
- âŒ è·Œç ´ MA99
- âŒ æ”¾é‡ä¸‹è·Œ
- âŒ é‡å¤§åˆ©ç©ºï¼ˆRug Pull é£é™©ã€é»‘å®¢æ”»å‡»ã€ä¸‹æ¶ç­‰ï¼‰

## å†³ç­–ä»ªè¡¨ç›˜æ ¸å¿ƒåŸåˆ™

1. **æ ¸å¿ƒç»“è®ºå…ˆè¡Œ**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°è¯¥å–
2. **åˆ†æŒä»“å»ºè®®**ï¼šç©ºä»“è€…å’ŒæŒä»“è€…ç»™ä¸åŒå»ºè®®
3. **ç²¾ç¡®ç‹™å‡»ç‚¹**ï¼šå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼ï¼ˆç¾å…ƒï¼‰ï¼Œä¸è¯´æ¨¡ç³Šçš„è¯
4. **æ£€æŸ¥æ¸…å•å¯è§†åŒ–**ï¼šç”¨ âœ…âš ï¸âŒ æ˜ç¡®æ˜¾ç¤ºæ¯é¡¹æ£€æŸ¥ç»“æœ
5. **é£é™©ä¼˜å…ˆçº§**ï¼šé“¾ä¸Šå¼‚å¸¸å’Œå·¨é²¸åŠ¨å‘è¦é†’ç›®æ ‡å‡º
6. **24/7 å¸‚åœºç‰¹æ€§**ï¼šåŠ å¯†è´§å¸å…¨å¤©å€™äº¤æ˜“ï¼Œæ—¶é—´æ•æ„Ÿæ€§æ›´é«˜"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API
        
        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯
        
        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"[AIåˆå§‹åŒ–] Gemini API Key: {'å·²é…ç½®' if gemini_key_valid else 'æœªé…ç½®'} (len={len(self._api_key or '')})")
        logger.info(f"[AIåˆå§‹åŒ–] OpenAI API Key: {'å·²é…ç½®' if config.openai_api_key else 'æœªé…ç½®'} (len={len(config.openai_api_key or '')})")
        logger.info(f"[AIåˆå§‹åŒ–] OpenAI Base URL: {config.openai_base_url or 'æœªé…ç½®'}")
        logger.info(f"[AIåˆå§‹åŒ–] OpenAI Model: {config.openai_model or 'æœªé…ç½®'}")
        
        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
        
        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰
        
        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()
        
        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and 
            not config.openai_api_key.startswith('your_') and 
            len(config.openai_api_key) > 10
        )
        
        if not openai_key_valid:
            # ä¿®å¤ï¼šä½¿ç”¨ INFO çº§åˆ«æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•
            logger.info(f"OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ (key={bool(config.openai_api_key)}, len={len(config.openai_api_key or '')})")
            return
        
        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return
        
        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url
            
            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹
        
        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai
            
            # é…ç½® API Key
            genai.configure(api_key=self._api_key)
            
            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback
            
            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ”¹ä¸ºä½¿ç”¨å¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆTavily/SerpAPIï¼‰é¢„å…ˆè·å–æ–°é—»
            
            # å°è¯•åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å°è¯•å¤‡é€‰æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥: {model_error}ï¼Œå°è¯•å¤‡é€‰æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å¤‡é€‰æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")
            
        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model = None
    
    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback
            
            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None
    
    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._openai_client.chat.completions.create(
                    model=self._current_model_name,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=generation_config.get('temperature', 0.7),
                    max_tokens=generation_config.get('max_output_tokens', 8192),
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    request_options={"timeout": 120}
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é™æµé”™è¯¯
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç»é‡è¯•äº†ä¸€åŠæ¬¡æ•°ä¸”è¿˜æ²¡åˆ‡æ¢è¿‡å¤‡é€‰æ¨¡å‹ï¼Œå°è¯•åˆ‡æ¢
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹ï¼Œç»§ç»­é‡è¯•")
                        else:
                            logger.warning("[Gemini] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹é‡è¯•")
                else:
                    # éé™æµé”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­é‡è¯•
                    logger.warning(f"[Gemini] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯• OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œåˆ‡æ¢åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å°è¯•æ‡’åŠ è½½åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        raise last_error or Exception("æ‰€æœ‰ AI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def analyze(
        self,
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå•ä¸ªåŠ å¯†è´§å¸
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + é“¾ä¸Šæ•°æ® + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            context: ä» crypto_analyzer è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¿ç»­è¯·æ±‚è§¦å‘é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–åŠ å¯†è´§å¸åç§°
        name = context.get('crypto_name') or context.get('stock_name')
        if not name or name.startswith('Token'):
            # å¤‡é€‰ï¼šä» realtime ä¸­è·å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # ä» code ä¸­æå– base è´§å¸ï¼Œç„¶åä»æ˜ å°„è¡¨è·å–
                base_symbol = code.split('/')[0] if '/' in code else code
                name = CRYPTO_NAME_MAP.get(base_symbol, base_symbol)
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è¯·é…ç½® Gemini API Key åé‡è¯•',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥ï¼ˆåŒ…å«æŠ€æœ¯é¢æ•°æ®å’Œæ–°é—»ï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # è·å–æ¨¡å‹åç§°
            model_name = getattr(self, '_current_model_name', None)
            if not model_name:
                model_name = getattr(self._model, '_model_name', 'unknown')
                if hasattr(self._model, 'model_name'):
                    model_name = self._model.model_name
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")
            
            # è®°å½•å®Œæ•´ prompt åˆ°æ—¥å¿—ï¼ˆINFOçº§åˆ«è®°å½•æ‘˜è¦ï¼ŒDEBUGè®°å½•å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")
            
            # è®¾ç½®ç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": 0.7,
                "max_output_tokens": 8192,
            }
            
            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ Gemini API (temperature={generation_config['temperature']}, max_tokens={generation_config['max_output_tokens']})...")
            
            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time
            
            # è®°å½•å“åº”ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] Gemini API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦")
            
            # è®°å½•å“åº”é¢„è§ˆï¼ˆINFOçº§åˆ«ï¼‰å’Œå®Œæ•´å“åº”ï¼ˆDEBUGçº§åˆ«ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(f"=== Gemini å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æå“åº”
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            
            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self,
        context: Dict[str, Any],
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè¯ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2.0 - åŠ å¯†è´§å¸ç‰ˆï¼‰
        
        åŒ…å«ï¼šæŠ€æœ¯æŒ‡æ ‡ã€å®æ—¶è¡Œæƒ…ã€é“¾ä¸ŠæŒ‡æ ‡ã€è¶‹åŠ¿åˆ†æã€æ–°é—»
        
        Args:
            context: æŠ€æœ¯é¢å’Œé“¾ä¸Šæ•°æ®ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼ºæ•°æ®ï¼‰
            name: åŠ å¯†è´§å¸åç§°ï¼ˆé»˜è®¤å€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†ç›–ï¼‰
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹
        """
        code = context.get('code', 'Unknown')
        
        # ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„åŠ å¯†è´§å¸åç§°
        crypto_name = context.get('crypto_name', name)
        if not crypto_name or crypto_name == f'Token{code}':
            # å°è¯•ä» code ä¸­æå– base è´§å¸
            base_symbol = code.split('/')[0] if '/' in code else code
            crypto_name = CRYPTO_NAME_MAP.get(base_symbol, base_symbol)
            
        today = context.get('today', {})
        
        # ========== æ„å»ºå†³ç­–ä»ªè¡¨ç›˜æ ¼å¼çš„è¾“å…¥ ==========
        prompt = f"""# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## ğŸ“Š åŠ å¯†è´§å¸åŸºç¡€ä¿¡æ¯
| é¡¹ç›® | æ•°æ® |
|------|------|
| äº¤æ˜“å¯¹/åˆçº¦ | **{code}** |
| å¸ç§åç§° | **{crypto_name}** |
| åˆ†ææ—¶é—´ | {context.get('date', 'æœªçŸ¥')} |
| æ•°æ®æ¥æº | {context.get('source', 'Exchange/DEX')} |

---

## ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

### æœ€æ–°è¡Œæƒ…
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| å½“å‰ä»·æ ¼ | ${today.get('close', 'N/A')} |
| å¼€ç›˜ä»· | ${today.get('open', 'N/A')} |
| æœ€é«˜ä»· | ${today.get('high', 'N/A')} |
| æœ€ä½ä»· | ${today.get('low', 'N/A')} |
| 24hæ¶¨è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| 24hæˆäº¤é‡ | {self._format_crypto_volume(today.get('volume'))} |
| 24hæˆäº¤é¢ | {self._format_crypto_amount(today.get('amount'))} |

### å‡çº¿ç³»ç»Ÿï¼ˆå…³é”®åˆ¤æ–­æŒ‡æ ‡ï¼‰
| å‡çº¿ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| MA7 | ${today.get('ma7', today.get('ma5', 'N/A'))} | çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA25 | ${today.get('ma25', today.get('ma10', 'N/A'))} | ä¸­æœŸè¶‹åŠ¿çº¿ |
| MA99 | ${today.get('ma99', today.get('ma20', 'N/A'))} | é•¿æœŸè¶‹åŠ¿çº¿ |
| å‡çº¿å½¢æ€ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šå¤´/ç©ºå¤´/ç¼ ç»• |
"""
        
        # æ·»åŠ å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆåŠ å¯†è´§å¸ç‰ˆï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å®æ—¶è¡Œæƒ…å¢å¼ºæ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| å½“å‰ä»·æ ¼ | ${rt.get('price', 'N/A')} | |
| **24hæˆäº¤é‡** | **{self._format_crypto_volume(rt.get('volume_24h'))}** | |
| **ä¹°å–æ¯”** | **{rt.get('buy_sell_ratio', 'N/A')}** | >1.2çœ‹æ¶¨, <0.8çœ‹è·Œ |
| å¸‚å€¼(MC) | {self._format_crypto_amount(rt.get('market_cap'))} | |
| å®Œå…¨ç¨€é‡Šå¸‚å€¼(FDV) | {self._format_crypto_amount(rt.get('fdv'))} | |
| FDV/MCæ¯” | {rt.get('fdv_mc_ratio', 'N/A')} | >3è­¦æƒ•æœªè§£é”ä»£å¸ |
| 7æ—¥æ¶¨è·Œå¹… | {rt.get('change_7d', 'N/A')}% | çŸ­æœŸè¡¨ç° |
| 30æ—¥æ¶¨è·Œå¹… | {rt.get('change_30d', 'N/A')}% | ä¸­æœŸè¡¨ç° |
"""
        
        # æ·»åŠ é“¾ä¸ŠæŒ‡æ ‡æ•°æ®ï¼ˆåŠ å¯†è´§å¸ç‰¹æœ‰ï¼‰
        if 'onchain' in context:
            onchain = context['onchain']
            top10_pct = onchain.get('top10_holding', 0)
            prompt += f"""
### é“¾ä¸ŠæŒ‡æ ‡æ•°æ®ï¼ˆå…³é”®é£é™©æŒ‡æ ‡ï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·æ ‡å‡† |
|------|------|----------|
| æŒæœ‰äººæ•° | {onchain.get('holder_count', 'N/A')} | è¶Šå¤šè¶Šå¥åº· |
| **Top10æŒä»“** | **{top10_pct:.1%}** | <50%è¾ƒåˆ†æ•£ |
| Top100æŒä»“ | {onchain.get('top100_holding', 0):.1%} | |
| æµåŠ¨æ€§æ·±åº¦(TVL) | {self._format_crypto_amount(onchain.get('tvl'))} | >$100Kå®‰å…¨ |
| 24hè½¬å…¥äº¤æ˜“æ‰€ | {self._format_crypto_amount(onchain.get('exchange_inflow'))} | å¤§é¢è­¦æƒ•æŠ›å‹ |
| é“¾ä¸Šå¥åº·åº¦ | {onchain.get('onchain_status', 'æœªçŸ¥')} | |
"""
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æç»“æœï¼ˆåŸºäºäº¤æ˜“ç†å¿µçš„é¢„åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_ma7 = trend.get('bias_ma7', trend.get('bias_ma5', 0))
            bias_warning = "ğŸš¨ è¶…è¿‡10%ï¼Œä¸¥ç¦è¿½é«˜ï¼" if bias_ma7 > 10 else ("âš ï¸ è­¦æˆ’åŒºé—´" if bias_ma7 > 5 else "âœ… å®‰å…¨èŒƒå›´")
            prompt += f"""
### è¶‹åŠ¿åˆ†æé¢„åˆ¤ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®š |
|------|------|------|
| è¶‹åŠ¿çŠ¶æ€ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡çº¿æ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA7>MA25>MA99ä¸ºå¤šå¤´ |
| è¶‹åŠ¿å¼ºåº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–ç¦»ç‡(MA7)** | **{bias_ma7:+.2f}%** | {bias_warning} |
| ä¹–ç¦»ç‡(MA25) | {trend.get('bias_ma25', trend.get('bias_ma10', 0)):+.2f}% | |
| é‡èƒ½çŠ¶æ€ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»ç»Ÿä¿¡å· | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»ç»Ÿè¯„åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»ç»Ÿåˆ†æç†ç”±
**ä¹°å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['æ— '])) if trend.get('signal_reasons') else '- æ— '}

**é£é™©å› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['æ— '])) if trend.get('risk_factors') else '- æ— '}
"""
        
        # æ·»åŠ æ˜¨æ—¥å¯¹æ¯”æ•°æ®
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡ä»·å˜åŒ–
- æˆäº¤é‡è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{volume_change}å€
- ä»·æ ¼è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°é—»æœç´¢ç»“æœï¼ˆé‡ç‚¹åŒºåŸŸï¼‰
        prompt += """
---

## ğŸ“° èˆ†æƒ…æƒ…æŠ¥
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{crypto_name}({code})** è¿‘7æ—¥çš„æ–°é—»æœç´¢ç»“æœï¼Œè¯·é‡ç‚¹æå–ï¼š
1. ğŸš¨ **é£é™©è­¦æŠ¥**ï¼šToken Unlockã€å·¨é²¸æŠ›å”®ã€é»‘å®¢æ”»å‡»ã€ä¸‹æ¶é£é™©
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šä¸Šçº¿å¤§æ‰€ã€åˆä½œå…¬å‘Šã€ç©ºæŠ•ã€ç”Ÿæ€è¿›å±•
3. ğŸ“Š **å¸‚åœºæƒ…ç»ª**ï¼šç¤¾äº¤åª’ä½“çƒ­åº¦ã€KOLè§‚ç‚¹

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è¯¥åŠ å¯†è´§å¸è¿‘æœŸçš„ç›¸å…³æ–°é—»ã€‚è¯·ä¸»è¦ä¾æ®æŠ€æœ¯é¢å’Œé“¾ä¸Šæ•°æ®è¿›è¡Œåˆ†æã€‚
"""
        
        # æ˜ç¡®çš„è¾“å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»åŠ¡

è¯·ä¸º **{crypto_name}({code})** ç”Ÿæˆã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚

### é‡ç‚¹å…³æ³¨ï¼ˆå¿…é¡»æ˜ç¡®å›ç­”ï¼‰ï¼š
1. â“ æ˜¯å¦æ»¡è¶³ MA7>MA25>MA99 å¤šå¤´æ’åˆ—ï¼Ÿ
2. â“ å½“å‰ä¹–ç¦»ç‡æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆ<10%ï¼‰ï¼Ÿâ€”â€” è¶…è¿‡10%å¿…é¡»æ ‡æ³¨"ä¸¥ç¦è¿½é«˜"
3. â“ é‡èƒ½æ˜¯å¦é…åˆï¼ˆç¼©é‡å›è°ƒ/æ”¾é‡çªç ´ï¼‰ï¼Ÿä¹°å–æ¯”æ˜¯å¦å¥åº·ï¼Ÿ
4. â“ é“¾ä¸ŠæŒ‡æ ‡æ˜¯å¦å¥åº·ï¼Ÿï¼ˆTop10æŒä»“ã€æµåŠ¨æ€§æ·±åº¦ã€å·¨é²¸åŠ¨å‘ï¼‰
5. â“ æ¶ˆæ¯é¢æœ‰æ— é‡å¤§åˆ©ç©ºï¼Ÿï¼ˆToken Unlockã€Rug Pullé£é™©ã€é»‘å®¢æ”»å‡»ç­‰ï¼‰

### å†³ç­–ä»ªè¡¨ç›˜è¦æ±‚ï¼š
- **æ ¸å¿ƒç»“è®º**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°/è¯¥å–/è¯¥ç­‰
- **æŒä»“åˆ†ç±»å»ºè®®**ï¼šç©ºä»“è€…æ€ä¹ˆåš vs æŒä»“è€…æ€ä¹ˆåš
- **å…·ä½“ç‹™å‡»ç‚¹ä½**ï¼šä¹°å…¥ä»·ã€æ­¢æŸä»·ã€ç›®æ ‡ä»·ï¼ˆç²¾ç¡®åˆ°å°æ•°ç‚¹å4ä½æˆ–åˆé€‚ç²¾åº¦ï¼‰
- **æ£€æŸ¥æ¸…å•**ï¼šæ¯é¡¹ç”¨ âœ…/âš ï¸/âŒ æ ‡è®°

è¯·è¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼å†³ç­–ä»ªè¡¨ç›˜ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡æ˜¾ç¤ºï¼ˆä¿ç•™æ—§æ–¹æ³•å…¼å®¹ï¼‰"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} äº¿"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} ä¸‡"
        else:
            return f"{volume:.0f}"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢æ˜¾ç¤ºï¼ˆä¿ç•™æ—§æ–¹æ³•å…¼å®¹ï¼‰"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} äº¿"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} ä¸‡"
        else:
            return f"{amount:.0f}"
    
    def _format_crypto_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–åŠ å¯†è´§å¸æˆäº¤é‡æ˜¾ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e9:
            return f"{volume / 1e9:.2f}B"
        elif volume >= 1e6:
            return f"{volume / 1e6:.2f}M"
        elif volume >= 1e3:
            return f"{volume / 1e3:.2f}K"
        else:
            return f"{volume:.2f}"
    
    def _format_crypto_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–åŠ å¯†è´§å¸æˆäº¤é¢/å¸‚å€¼æ˜¾ç¤ºï¼ˆç¾å…ƒï¼‰"""
        if amount is None:
            return 'N/A'
        if amount >= 1e12:
            return f"${amount / 1e12:.2f}T"
        elif amount >= 1e9:
            return f"${amount / 1e9:.2f}B"
        elif amount >= 1e6:
            return f"${amount / 1e6:.2f}M"
        elif amount >= 1e3:
            return f"${amount / 1e3:.2f}K"
        else:
            return f"${amount:.2f}"
    
    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """
        è§£æ Gemini å“åº”ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ç‰ˆï¼‰
        
        å°è¯•ä»å“åº”ä¸­æå– JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å« dashboard å­—æ®µ
        å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ™ºèƒ½æå–æˆ–è¿”å›é»˜è®¤ç»“æœ
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®°
            cleaned_text = response_text
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            # å°è¯•æ‰¾åˆ° JSON å†…å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                json_str = self._fix_json_string(json_str)
                
                data = json.loads(json_str)
                
                # æå– dashboard æ•°æ®
                dashboard = data.get('dashboard', None)
                
                # è§£ææ‰€æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼é˜²æ­¢ç¼ºå¤±
                return AnalysisResult(
                    code=code,
                    name=name,
                    # æ ¸å¿ƒæŒ‡æ ‡
                    sentiment_score=int(data.get('sentiment_score', 50)),
                    trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                    operation_advice=data.get('operation_advice', 'æŒæœ‰'),
                    confidence_level=data.get('confidence_level', 'ä¸­'),
                    # å†³ç­–ä»ªè¡¨ç›˜
                    dashboard=dashboard,
                    # èµ°åŠ¿åˆ†æ
                    trend_analysis=data.get('trend_analysis', ''),
                    short_term_outlook=data.get('short_term_outlook', ''),
                    medium_term_outlook=data.get('medium_term_outlook', ''),
                    # æŠ€æœ¯é¢
                    technical_analysis=data.get('technical_analysis', ''),
                    ma_analysis=data.get('ma_analysis', ''),
                    volume_analysis=data.get('volume_analysis', ''),
                    pattern_analysis=data.get('pattern_analysis', ''),
                    # åŸºæœ¬é¢
                    fundamental_analysis=data.get('fundamental_analysis', ''),
                    sector_position=data.get('sector_position', ''),
                    company_highlights=data.get('company_highlights', ''),
                    # æƒ…ç»ªé¢/æ¶ˆæ¯é¢
                    news_summary=data.get('news_summary', ''),
                    market_sentiment=data.get('market_sentiment', ''),
                    hot_topics=data.get('hot_topics', ''),
                    # ç»¼åˆ
                    analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                    key_points=data.get('key_points', ''),
                    risk_warning=data.get('risk_warning', ''),
                    buy_reason=data.get('buy_reason', ''),
                    # å…ƒæ•°æ®
                    search_performed=data.get('search_performed', False),
                    data_sources=data.get('data_sources', 'æŠ€æœ¯é¢æ•°æ®'),
                    success=True,
                )
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                return self._parse_text_response(response_text, code, name)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡æœ¬æå–")
            return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
        import re
        
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """ä»çº¯æ–‡æœ¬å“åº”ä¸­å°½å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å°è¯•è¯†åˆ«å…³é”®è¯æ¥åˆ¤æ–­æƒ…ç»ª
        sentiment_score = 50
        trend = 'éœ‡è¡'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        positive_keywords = ['çœ‹å¤š', 'ä¹°å…¥', 'ä¸Šæ¶¨', 'çªç ´', 'å¼ºåŠ¿', 'åˆ©å¥½', 'åŠ ä»“', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'å–å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±åŠ¿', 'åˆ©ç©º', 'å‡ä»“', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'ä¹°å…¥'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'å–å‡º'
        
        # æˆªå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'æ— åˆ†æç»“æœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±è´¥ï¼Œä»…ä¾›å‚è€ƒ',
            risk_warning='åˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self,
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šä¸ªåŠ å¯†è´§å¸
        
        æ³¨æ„ï¼šä¸ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é—´ä¼šæœ‰å»¶è¿Ÿ
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ‹ŸåŠ å¯†è´§å¸ä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        'code': 'BTC/USDT',
        'crypto_name': 'Bitcoin',
        'date': '2026-01-17',
        'source': 'Binance',
        'today': {
            'open': 42500.0,
            'high': 43200.0,
            'low': 42100.0,
            'close': 43000.0,
            'volume': 15000000000,  # 24hæˆäº¤é‡ï¼ˆç¾å…ƒï¼‰
            'amount': 350000,  # æˆäº¤é‡ï¼ˆBTCï¼‰
            'pct_chg': 1.18,
            'ma7': 42800.0,
            'ma25': 41500.0,
            'ma99': 38000.0,
        },
        'ma_status': 'å¤šå¤´æ’åˆ— ğŸ“ˆ',
        'realtime': {
            'price': 43000.0,
            'volume_24h': 15000000000,
            'buy_sell_ratio': 1.15,
            'market_cap': 840000000000,
            'fdv': 840000000000,
            'fdv_mc_ratio': 1.0,
            'change_7d': 5.2,
            'change_30d': 12.8,
        },
        'onchain': {
            'holder_count': 50000000,
            'top10_holding': 0.05,
            'top100_holding': 0.12,
            'tvl': 50000000000,
            'exchange_inflow': 500000000,
            'onchain_status': 'å¥åº·',
        },
        'trend_analysis': {
            'trend_status': 'ä¸Šå‡è¶‹åŠ¿',
            'ma_alignment': 'å¤šå¤´æ’åˆ—',
            'trend_strength': 75,
            'bias_ma7': 0.47,
            'bias_ma25': 3.61,
            'volume_status': 'æ”¾é‡',
            'volume_trend': 'æˆäº¤é‡å¢åŠ ',
            'buy_signal': 'ä¹°å…¥',
            'signal_score': 78,
            'signal_reasons': ['å‡çº¿å¤šå¤´æ’åˆ—', 'ä¹–ç¦»ç‡åœ¨å®‰å…¨èŒƒå›´', 'ä¹°å–æ¯”å¥åº·'],
            'risk_factors': ['æ¥è¿‘çŸ­æœŸå‹åŠ›ä½'],
        },
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== åŠ å¯†è´§å¸ AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
